{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3CqHRm6osBv",
        "outputId": "34b62bb4-2569-4bd7-ab07-477a8ae26d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load (likely expired) https://storage.googleapis.com/kaggle-data-sets/209316/999617/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240423%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240423T014710Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=1ed7ea0e77c95089e0cd55beefe75fcfb8dfb9dcfde954246e33380f26df57d7663dbec1a67f1e411a59874c55452b3766dac2ed3b45a1a60f3cb224a9172b626868c72e69ec03cafa437c9d42433a3bc67f86712a49a039519e42ec9fa05f331c3ded4750ef054d2ccbcab7174343ea2afbb0d7df91eb785ddb04b0b773a02178027c0ddc2008382645f5634eba19b721d5fc1da3752c10dddf104ce073b8354ba2d87859311115623b4807cafe437751eb5f92c00d141779a05a1631b0db139d1de52916b25906c087e44330c337fb14df576fe7df528504d54ac679fc7ba732096c97244e65b259376ada90e52135cb825b56bd910f6d29ae26cf22a594d2 to path /kaggle/input/breakhis\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'breakhis:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F209316%2F999617%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240423%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240423T014710Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D1ed7ea0e77c95089e0cd55beefe75fcfb8dfb9dcfde954246e33380f26df57d7663dbec1a67f1e411a59874c55452b3766dac2ed3b45a1a60f3cb224a9172b626868c72e69ec03cafa437c9d42433a3bc67f86712a49a039519e42ec9fa05f331c3ded4750ef054d2ccbcab7174343ea2afbb0d7df91eb785ddb04b0b773a02178027c0ddc2008382645f5634eba19b721d5fc1da3752c10dddf104ce073b8354ba2d87859311115623b4807cafe437751eb5f92c00d141779a05a1631b0db139d1de52916b25906c087e44330c337fb14df576fe7df528504d54ac679fc7ba732096c97244e65b259376ada90e52135cb825b56bd910f6d29ae26cf22a594d2'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teFJ5wzSsdf5",
        "outputId": "91e3f677-695d-4261-d9d5-3c8c4d9c07c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/611.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/611.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m532.5/611.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkF5K5iSosB4",
        "outputId": "cc1ee33a-7cc6-4a64-ff59-921182051ddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from keras.utils import plot_model\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import BatchNormalization, Conv2D, Conv2DTranspose, Dense, Dropout, Flatten, GlobalAveragePooling2D, Input, MaxPooling2D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score\n",
        "from tensorflow.keras.applications import ResNet50V2, VGG16, InceptionV3\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import load_img,img_to_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPRwsf-nosB6"
      },
      "outputs": [],
      "source": [
        "folder = '/kaggle/input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast'\n",
        "folder_path = pathlib.Path(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "vXIZuLxmosB7",
        "outputId": "267f1a0e-f083-4b7d-d432-040c6fbaa330"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-001.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-156ada6f9c8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mphoto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-001.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mphoto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-001.png'"
          ]
        }
      ],
      "source": [
        "photo = load_img('/kaggle/input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign/SOB/adenosis/SOB_B_A_14-22549AB/100X/SOB_B_A-14-22549AB-100-001.png')\n",
        "print(photo)\n",
        "photo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAfHRpF8osB8"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 128\n",
        "DIM = (IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "ZOOM = [.99, 1.01]\n",
        "BRIGHT_RANGE = [0.8, 1.2]\n",
        "HORZ_FLIP = True\n",
        "FILL_MODE = \"constant\"\n",
        "DATA_FORMAT = \"channels_last\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jLC2snDosB9"
      },
      "outputs": [],
      "source": [
        "train_generator = ImageDataGenerator(rescale = 1./255, brightness_range=BRIGHT_RANGE, zoom_range=ZOOM,\n",
        "                                     data_format=DATA_FORMAT, fill_mode=FILL_MODE, horizontal_flip=HORZ_FLIP)\n",
        "train_data_gen = train_generator.flow_from_directory(directory=folder, target_size=DIM, batch_size=6500, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLqklZslosB-"
      },
      "outputs": [],
      "source": [
        "train_data, train_labels = train_data_gen.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVixU-oOosB_"
      },
      "outputs": [],
      "source": [
        "#Synthetic Minority Over-sampling Technique\n",
        "sm = SMOTE(random_state=42)\n",
        "\n",
        "train_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_SIZE * IMG_SIZE * 3), train_labels)\n",
        "\n",
        "print(train_data.shape, train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSi0aO30osCA"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
        "print(train_data.shape, train_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH-XnAD1osCA"
      },
      "outputs": [],
      "source": [
        "train_labels = train_labels.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4gdEhSCosCB"
      },
      "outputs": [],
      "source": [
        "for i in range(2):\n",
        "    plt.subplot(2,2,1+i)\n",
        "    plt.title(train_labels[i])\n",
        "    plt.imshow(train_data[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tA85S1QosCB"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7L92oCq9osCC"
      },
      "outputs": [],
      "source": [
        "train_data, test_data, train_labels,test_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)\n",
        "\n",
        "train_data, val_data, train_labels,val_labels = train_test_split(train_data, train_labels, test_size = 0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydigK7noosCF"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "K.set_image_data_format('channels_last')\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2xEq7hcosCF"
      },
      "outputs": [],
      "source": [
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvoO0HyDosCG"
      },
      "outputs": [],
      "source": [
        "vgg16_model = Sequential([\n",
        "    vgg_model,\n",
        "    Flatten(),\n",
        "    BatchNormalization(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    BatchNormalization(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "], name=\"vgg16_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKJW0oVlosCG"
      },
      "outputs": [],
      "source": [
        "vgg16_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sMOF6PWosCG"
      },
      "outputs": [],
      "source": [
        "plot_model(vgg16_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0rjCTziosCG"
      },
      "outputs": [],
      "source": [
        "# Fit the model to the training data\n",
        "vgg16_history = vgg16_model.fit(train_data, train_labels, epochs=1, verbose=1)\n",
        "\n",
        "# Store accuracy and loss history for each epoch\n",
        "vgg16_accuracy_history = vgg16_history.history['accuracy']\n",
        "vgg16_loss_history = vgg16_history.history['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3-Z8AB2osCH"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = vgg16_model.evaluate(test_data, test_labels)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMlTMFiOosCH"
      },
      "outputs": [],
      "source": [
        "y_pred = np.round(vgg16_model.predict(test_data)).astype(int)\n",
        "\n",
        "target_names = ['Benign', 'Malignant']\n",
        "report = classification_report(test_labels, y_pred, target_names=target_names, output_dict=True)\n",
        "\n",
        "for target_name in target_names:\n",
        "    precision = report[target_name]['precision']\n",
        "    recall = report[target_name]['recall']\n",
        "    f1_score = report[target_name]['f1-score']\n",
        "\n",
        "# Average precision, recall, and F1-score\n",
        "avg_precision = report['weighted avg']['precision']\n",
        "avg_recall = report['weighted avg']['recall']\n",
        "avg_f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "print('Average Precision: {:.2f}%'.format(avg_precision*100))\n",
        "print('Average Recall: {:.2f}%'.format(avg_recall*100))\n",
        "print('Average F1 Score: {:.2f}%'.format(avg_f1_score*100))\n",
        "\n",
        "vgg16_precision = avg_precision\n",
        "vgg16_recall = avg_recall\n",
        "vgg16_f1score = avg_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4sBCclaosCH"
      },
      "outputs": [],
      "source": [
        "# Get predicted probabilities for test set\n",
        "y_pred_prob_tl = vgg16_model.predict(test_data)\n",
        "\n",
        "# Get false positive rate, true positive rate, and thresholds\n",
        "fpr, tpr, thresholds = roc_curve(test_labels, y_pred_prob_tl)\n",
        "\n",
        "# Compute AUC score\n",
        "roc_auc = roc_auc_score(test_labels, y_pred_prob_tl)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(4,3))\n",
        "plt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHGgJRbHosCI"
      },
      "outputs": [],
      "source": [
        "y_scores = vgg16_model.predict(test_data)\n",
        "precision, recall, _ = precision_recall_curve(test_labels, y_scores)\n",
        "\n",
        "plt.figure(figsize=(4,3)) # set figure size\n",
        "plt.plot(recall, precision, color='b')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-dSlpIEosCI"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trained ResNet50V2 model\n",
        "resnet50v2 = ResNet50V2(include_top=False, weights='imagenet', input_shape=(128, 128, 3))\n",
        "\n",
        "# Freeze the layers in the pre-trained model\n",
        "for layer in resnet50v2.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW2J3xuSosCI"
      },
      "outputs": [],
      "source": [
        "ResNet50V2_model = Sequential([\n",
        "    resnet50v2,\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "], name=\"ResNet50V2_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cY-fE7PosCI"
      },
      "outputs": [],
      "source": [
        "ResNet50V2_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ResNet50V2_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gonjDIrtosCJ"
      },
      "outputs": [],
      "source": [
        "plot_model(ResNet50V2_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5biI1TQosCJ"
      },
      "outputs": [],
      "source": [
        "ResNet50V2_model_history = ResNet50V2_model.fit(train_data, train_labels, epochs=1, verbose=1)\n",
        "\n",
        "# Store accuracy and loss history for each epoch\n",
        "ResNet_accuracy_history = ResNet50V2_model_history.history['accuracy']\n",
        "ResNet_loss_history = ResNet50V2_model_history.history['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lN4zIM9wosCJ"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = ResNet50V2_model.evaluate(test_data, test_labels)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-Xc5FljosCU"
      },
      "outputs": [],
      "source": [
        "y_pred = np.round(ResNet50V2_model.predict(test_data)).astype(int)\n",
        "\n",
        "target_names = ['Benign', 'Malignant']\n",
        "report = classification_report(test_labels, y_pred, target_names=target_names, output_dict=True)\n",
        "\n",
        "for target_name in target_names:\n",
        "    precision = report[target_name]['precision']\n",
        "    recall = report[target_name]['recall']\n",
        "    f1_score = report[target_name]['f1-score']\n",
        "\n",
        "# Average precision, recall, and F1-score\n",
        "avg_precision = report['weighted avg']['precision']\n",
        "avg_recall = report['weighted avg']['recall']\n",
        "avg_f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "print('Average Precision: {:.2f}%'.format(avg_precision*100))\n",
        "print('Average Recall: {:.2f}%'.format(avg_recall*100))\n",
        "print('Average F1 Score: {:.2f}%'.format(avg_f1_score*100))\n",
        "\n",
        "ResNet_precision = avg_precision\n",
        "ResNet_recall = avg_recall\n",
        "ResNet_f1score = avg_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZBAS62HosCV"
      },
      "outputs": [],
      "source": [
        "# Get predicted probabilities for test set\n",
        "y_pred = ResNet50V2_model.predict(test_data)\n",
        "\n",
        "# Get false positive rate, true positive rate, and thresholds\n",
        "fpr, tpr, thresholds = roc_curve(test_labels, y_pred_prob)\n",
        "\n",
        "# Compute AUC score\n",
        "roc_auc = roc_auc_score(test_labels, y_pred_prob)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(4,3))\n",
        "plt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIBq5XxZosCV"
      },
      "outputs": [],
      "source": [
        "y_scores = ResNet50V2_model.predict(test_data)\n",
        "precision, recall, _ = precision_recall_curve(test_labels, y_scores)\n",
        "\n",
        "plt.figure(figsize=(4,3)) # set figure size\n",
        "plt.plot(recall, precision, color='b')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rux5jDs6osCV"
      },
      "source": [
        "#  **Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlhA36m-osCY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Evaluate the VGG16 model\n",
        "vgg16_loss, vgg16_accuracy = vgg16_model.evaluate(test_data, test_labels)\n",
        "\n",
        "# Evaluate the ResNet50V2 model\n",
        "resnet_loss, resnet_accuracy = ResNet50V2_model.evaluate(test_data, test_labels)\n",
        "\n",
        "print('+-------------------------------------------------------+')\n",
        "print('|{\"Model Evaluation Results\"} |   {\"loss\"} | {\"accuracy\"}             |')\n",
        "print('+-----------------+---------------+---------------------+')\n",
        "print(f'|    {\"CNN Model\":<15} |    {cnn_loss:.2f}      |        {cnn_accuracy:.2f}        |')\n",
        "print('+-----------------+---------------+---------------------+')\n",
        "\n",
        "\n",
        "print(f'|   {\"VGG16 Model\":<15} |    {vgg16_loss:.2f}      |        {vgg16_accuracy:.2f}        |')\n",
        "print('+-----------------+---------------+---------------------+')\n",
        "\n",
        "\n",
        "print(f'| {\"ResNet50V2 Model\":<15} |    {resnet_loss:.2f}      |        {resnet_accuracy:.2f}         |')\n",
        "print('+-----------------+---------------+---------------------+')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYPEBiEeosCZ"
      },
      "outputs": [],
      "source": [
        "# Extract the accuracy history for each model every 5 epochs\n",
        "\n",
        "vgg16_history = vgg16_accuracy_history[::5]\n",
        "resnet_history = ResNet_accuracy_history[::5]\n",
        "\n",
        "# Plot the accuracy history for each model\n",
        "\n",
        "plt.plot(vgg16_history, label='VGG16')\n",
        "plt.plot(resnet_history, label='ResNet50V2')\n",
        "\n",
        "# Set the plot title and axis labels\n",
        "plt.title('Training Accuracy by Epoch (Every 5 Epochs)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me8E3M0SosCa"
      },
      "outputs": [],
      "source": [
        "# Extract the loss history for each model every 5 epochs\n",
        "cnn_history = cnn_loss_history[::5]\n",
        "vgg16_history = vgg16_loss_history[::5]\n",
        "resnet_history = ResNet_loss_history[::5]\n",
        "\n",
        "# Plot the loss history for each model\n",
        "plt.plot(cnn_history, label='CNN')\n",
        "plt.plot(vgg16_history, label='VGG16')\n",
        "plt.plot(resnet_history, label='ResNet50V2')\n",
        "\n",
        "# Set the plot title and axis labels\n",
        "plt.title('Training Loss by Epoch (Every 5 Epochs)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Add a legend to the plot\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BdHBEzcosCa"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to store the metrics\n",
        "metrics_dict = {\n",
        "    'Model': ['CNN', 'VGG16', 'ResNet50V2'],\n",
        "   'Avg Precision': [cnn_precision*100, vgg16_precision*100, ResNet_precision*100],\n",
        "        'Avg Recall': [cnn_recall*100, vgg16_recall*100, ResNet_recall*100],\n",
        "        'Avg F1-Score': [cnn_f1score*100, vgg16_f1score*100, ResNet_f1score*100]\n",
        "}\n",
        "\n",
        "# Create a pandas DataFrame from the dictionary\n",
        "metrics_df = pd.DataFrame(metrics_dict)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(metrics_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}